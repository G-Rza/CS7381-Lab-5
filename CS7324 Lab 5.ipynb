{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ce9c10",
   "metadata": {},
   "source": [
    "# Lab Assignment Five: Wide and Deep Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6f26b",
   "metadata": {},
   "source": [
    "Team Members: Stephen Palmier, Bryn McCann, Jaime Garza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec5485",
   "metadata": {},
   "source": [
    "# Part 1 - Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd9d12b",
   "metadata": {},
   "source": [
    "1.1 Define and Prepare Class Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d9446ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t-0.7916372063774119\n",
      "  (0, 1)\t0.3837438115303823\n",
      "  (0, 2)\t-0.03502058299434622\n",
      "  (0, 3)\t-0.6342676503297628\n",
      "  (0, 4)\t-0.28607889796756397\n",
      "  (0, 5)\t-0.4681847495753422\n",
      "  (0, 6)\t-0.5947328560432157\n",
      "  (0, 7)\t-0.5605763984427392\n",
      "  (0, 8)\t-0.2681582960265635\n",
      "  (0, 9)\t4.638520945486807\n",
      "  (0, 10)\t-0.1781496960135872\n",
      "  (0, 11)\t-0.5479739306284881\n",
      "  (0, 12)\t-0.2991564865199796\n",
      "  (0, 13)\t0.49722548702230135\n",
      "  (0, 14)\t0.46730467049690233\n",
      "  (0, 15)\t0.8324057557723143\n",
      "  (0, 16)\t-0.04576051100999835\n",
      "  (0, 22)\t1.0\n",
      "  (0, 40)\t1.0\n",
      "  (0, 91)\t1.0\n",
      "  (0, 97)\t1.0\n",
      "  (0, 98)\t1.0\n",
      "  (0, 113)\t1.0\n",
      "  (0, 120)\t1.0\n",
      "  (0, 123)\t1.0\n",
      "  :\t:\n",
      "  (4, 0)\t-0.7916372063774119\n",
      "  (4, 1)\t1.3448431221578148\n",
      "  (4, 2)\t0.1322445816520758\n",
      "  (4, 3)\t0.503796375562582\n",
      "  (4, 4)\t-0.28607889796756397\n",
      "  (4, 5)\t1.7887428440927218\n",
      "  (4, 6)\t1.218684456508622\n",
      "  (4, 7)\t0.3127320599904302\n",
      "  (4, 8)\t0.2586748950384158\n",
      "  (4, 9)\t-0.4644870326417867\n",
      "  (4, 10)\t0.7508896112485252\n",
      "  (4, 11)\t0.6781102312892552\n",
      "  (4, 12)\t0.73413980420103\n",
      "  (4, 13)\t0.49722548702230135\n",
      "  (4, 14)\t0.46730467049690233\n",
      "  (4, 15)\t0.8324057557723143\n",
      "  (4, 16)\t-0.04576051100999835\n",
      "  (4, 22)\t1.0\n",
      "  (4, 40)\t1.0\n",
      "  (4, 91)\t1.0\n",
      "  (4, 97)\t1.0\n",
      "  (4, 100)\t1.0\n",
      "  (4, 113)\t1.0\n",
      "  (4, 120)\t1.0\n",
      "  (4, 123)\t1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset from the specified path\n",
    "file_path = r\"C:\\Users\\jaime\\OneDrive - Southern Methodist University\\Courses\\CS7324\\Labs\\Lab 5\\AirBNB\\Unit_1_Project_Dataset.csv\"\n",
    "airbnb_data = pd.read_csv(file_path)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = ['host_since_year', 'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'guests_included', 'minimum_nights', 'number_of_reviews', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value']\n",
    "categorical_cols = ['neighbourhood_cleansed', 'city', 'state', 'country', 'property_type', 'room_type', 'bed_type', 'host_response_time']\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Prepare features and target\n",
    "features = airbnb_data.drop(['price', 'host_name', 'host_since_anniversary', 'zipcode'], axis=1)\n",
    "target = airbnb_data['price']\n",
    "\n",
    "# Applying preprocessing\n",
    "X = preprocessor.fit_transform(features)\n",
    "\n",
    "# Stratified split based on neighbourhood to ensure each train-test set is representative\n",
    "# Note: if 'neighbourhood_cleansed' contains NaN values, you will need to handle these before stratifying\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=42, stratify=features['neighbourhood_cleansed'])\n",
    "\n",
    "# a Print of the first few entries of the train data to verify\n",
    "print(X_train[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed2b79",
   "metadata": {},
   "source": [
    "Part 1 explained: \n",
    "* 1.1 We standardized numerical features to guarantee that no single property dominated because of its size. We employed one-hot encoding to convert categorical features into machine-readable format. A regression task defines the price of the target variable. Irrelevant characteristics like host_name and zipcode are deleted to help the model focus on more important predictions.\n",
    "\n",
    "* 1.2: Justification: This code prepares the Airbnb dataset by loading it from a specified file location using the 'pd.read_csv()' function. It then discovers the numerical and categorical columns that are necessary for preprocessing. A 'ColumnTransformer' is used to scale numerical columns, whilst categorical columns are encoded once to ensure interoperability with machine learning approaches. To prepare the features, unnecessary columns like ''price'', ''host_name'', ''host_since_anniversary'', and ''zipcode'' are deleted, and the target variable ''price'' is extracted separately. Following the preparation operations, the dataset is stratified and separated into training and testing sets using the ''neighborhood_cleansed'' feature. Finally, the first five training data entries are presented to confirm that the preparation and splitting methods were followed appropriately. \n",
    "\n",
    "* 1.3: In order to evaluate the algorithm's performance on the Airbnb dataset, we intend toÂ use mean absolute error (MAE) or mean squared error (MSE) rather than accuracy. MAE gives an interpretable measure of the average size of errors in anticipated price values, which is critical for comprehending price differences from real prices. MSE, while less interpretable, has sensitivity to big errors, which is useful for finding outliers. Given the business case's emphasis on accurately anticipating listing prices for informed decision-making by hosts and guests, MAE and MSE are well suited to the goal of reducing prediction errors in the Airbnb domain.\n",
    "\n",
    "* 1.4: The code utilizes the `train_test_split` function to divide the data into training and testing sets. Stratified splitting based on the 'neighbourhood_cleansed' column ensures the representation of neighborhoods in both sets. This approach aligns with practical scenarios where maintaining the distribution of important categorical variables is crucial. The code directly reflects this strategy, guaranteeing a realistic mirroring of how the algorithm would be used in practice for model evaluation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bd9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
